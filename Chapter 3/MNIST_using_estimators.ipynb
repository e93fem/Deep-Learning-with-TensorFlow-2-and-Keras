{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training and eval data\n",
    "((train_data, train_labels),\n",
    " (eval_data, eval_labels)) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data/np.float32(255)\n",
    "train_labels = train_labels.astype(np.int32)  \n",
    "\n",
    "eval_data = eval_data/np.float32(255)\n",
    "eval_labels = eval_labels.astype(np.int32)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, '2')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = np.random.randint(0,len(train_data))\n",
    "plt.imshow(train_data[idx], cmap='gray')\n",
    "plt.title(str(train_labels[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = [tf.feature_column.numeric_column(\"x\", shape=[28, 28])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'mnist_model/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000002156E4F5C88>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "classifier = tf.estimator.LinearClassifier(\n",
    "    feature_columns=feature_columns,\n",
    "    n_classes=10,\n",
    "    model_dir=\"mnist_model/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_fn =  tf.compat.v1.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": train_data},\n",
    "    y=train_labels,\n",
    "    batch_size=100,\n",
    "    num_epochs=None,\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from mnist_model/model.ckpt-110\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 110 into mnist_model/model.ckpt.\n",
      "INFO:tensorflow:loss = 2.3127978, step = 110\n",
      "INFO:tensorflow:global_step/sec: 290.087\n",
      "INFO:tensorflow:loss = 2.2965958, step = 210 (0.329 sec)\n",
      "INFO:tensorflow:global_step/sec: 444.832\n",
      "INFO:tensorflow:loss = 2.301978, step = 310 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 455.01\n",
      "INFO:tensorflow:loss = 2.294956, step = 410 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.766\n",
      "INFO:tensorflow:loss = 2.2938795, step = 510 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 444.388\n",
      "INFO:tensorflow:loss = 2.295445, step = 610 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 448.474\n",
      "INFO:tensorflow:loss = 2.2923105, step = 710 (0.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 398.318\n",
      "INFO:tensorflow:loss = 2.2965038, step = 810 (0.251 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.77\n",
      "INFO:tensorflow:loss = 2.2934988, step = 910 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.249\n",
      "INFO:tensorflow:loss = 2.2891164, step = 1010 (0.219 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1110 into mnist_model/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 2.2894988.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.linear.LinearClassifierV2 at 0x2156ee16648>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.train(input_fn=train_input_fn, steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_input_fn =  tf.compat.v1.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": eval_data},\n",
    "    y=eval_labels,\n",
    "    num_epochs=1,\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-02-11T21:11:02Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from mnist_model/model.ckpt-1110\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2020-02-11-21:11:03\n",
      "INFO:tensorflow:Saving dict for global step 1110: accuracy = 0.1997, average_loss = 2.289342, global_step = 1110, loss = 2.2893915\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1110: mnist_model/model.ckpt-1110\n",
      "{'accuracy': 0.1997, 'average_loss': 2.289342, 'loss': 2.2893915, 'global_step': 1110}\n"
     ]
    }
   ],
   "source": [
    "eval_results = classifier.evaluate(input_fn=val_input_fn)\n",
    "print(eval_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
